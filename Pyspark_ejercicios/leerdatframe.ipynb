{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZOMNA DE IMPORT\n",
    "\n",
    " ÂºPara poder usar pyspark en VScode tenemos que usar findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, col\n",
    "from pyspark.sql.types import StructField, StructType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([\n",
    "    (1, 2., 'string1', date(2000, 1, 1), datetime(2000, 1, 1, 12, 0)),\n",
    "    (2, 3., 'string2', date(2000, 2, 1), datetime(2000, 1, 2, 12, 0)),\n",
    "    (3, 4., 'string3', date(2000, 3, 1), datetime(2000, 1, 3, 12, 0))\n",
    "], schema='a long, b double, c string, d date, e timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+----------+-------------------+\n",
      "|  a|  b|      c|         d|                  e|\n",
      "+---+---+-------+----------+-------------------+\n",
      "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
      "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n",
      "|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|\n",
      "+---+---+-------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = spark.createDataFrame([\n",
    "    (\"Jorge\", 10, 8, 5, None),\n",
    "    (\"Fito\", 6, 7, 8, 10),\n",
    "    (\"Percy\", None, None, None, 5)\n",
    "],[\"Nombre\", \"Nota1\", \"Nota2\", \"Nota3\", \"Nota4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----+-----+-----+\n",
      "|Nombre|Nota1|Nota2|Nota3|Nota4|\n",
      "+------+-----+-----+-----+-----+\n",
      "| Jorge|   10|    8|    5| null|\n",
      "|  Fito|    6|    7|    8|   10|\n",
      "| Percy| null| null| null|    5|\n",
      "+------+-----+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "uiid = \"ID_UIID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nota1', 'Nota2', 'Nota3', 'Nota4']\n"
     ]
    }
   ],
   "source": [
    "lista_notas = [x for x in df_data.columns if \"Nota\" in x]\n",
    "print(lista_notas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = df_data.withColumn(\"ID_UIID\", expr(\"uuid()\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+-----+-----+\n",
      "|             ID_UIID|Nota1|Nota2|Nota3|Nota4|\n",
      "+--------------------+-----+-----+-----+-----+\n",
      "|f00c9741-48d5-47a...|   10|    8|    5| null|\n",
      "|3c65bf93-c465-463...|    6|    7|    8|   10|\n",
      "|de05c527-4c85-4e0...| null| null| null|    5|\n",
      "+--------------------+-----+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_select = df_info.select(\"ID_UIID\", *lista_notas)\n",
    "df_select.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "suma = 0\n",
    "contador = 0\n",
    "media = 0\n",
    "lista_medias_nostas = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rows_data in df_select.collect():\n",
    "    id = rows_data[0]\n",
    "    # print(f\"ID = {id}\")\n",
    "    for x in range(1,len(rows_data)):\n",
    "        # print(rows_data[x])\n",
    "        notas = rows_data[x]\n",
    "        if notas is not None:\n",
    "            suma += notas\n",
    "            contador += 1\n",
    "    if suma > 0:\n",
    "        media = (suma / contador)\n",
    "        lista_medias_nostas.append([id, media])\n",
    "    suma = 0\n",
    "    contador = 0\n",
    "    media = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['f00c9741-48d5-47a7-9674-67a990ec443d', 7.666666666666667], ['3c65bf93-c465-463c-9926-aee0ce01f3e3', 7.75], ['de05c527-4c85-4e00-8074-e591bc10832e', 5.0]]\n"
     ]
    }
   ],
   "source": [
    "print(lista_medias_nostas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media = spark.sparkContext.parallelize(lista_medias_nostas).toDF([\"ID_UIID\", \"MET_NOTAS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_final = df_info.join(df_media, df_info.ID_UIID == df_media.ID_UIID, 'left').drop(\"ID_UIID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----+-----+-----+-----------------+\n",
      "|Nombre|Nota1|Nota2|Nota3|Nota4|        MET_NOTAS|\n",
      "+------+-----+-----+-----+-----+-----------------+\n",
      "|  Fito|    6|    7|    8|   10|             7.75|\n",
      "| Percy| null| null| null|    5|              5.0|\n",
      "| Jorge|   10|    8|    5| null|7.666666666666667|\n",
      "+------+-----+-----+-----+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_media_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Nombre: string (nullable = true)\n",
      " |-- Nota1: long (nullable = true)\n",
      " |-- Nota2: long (nullable = true)\n",
      " |-- Nota3: long (nullable = true)\n",
      " |-- Nota4: long (nullable = true)\n",
      " |-- MET_NOTAS: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_media_final.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
