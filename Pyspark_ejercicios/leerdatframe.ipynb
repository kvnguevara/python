{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZOMNA DE IMPORT\n",
    "\n",
    " ÂºPara poder usar pyspark en VScode tenemos que usar findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, col, udf, array\n",
    "from pyspark.sql.types import StructField, StructType, StringType, DecimalType, LongType, FloatType\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([\n",
    "    (1, 2., 'string1', date(2000, 1, 1), datetime(2000, 1, 1, 12, 0)),\n",
    "    (2, 3., 'string2', date(2000, 2, 1), datetime(2000, 1, 2, 12, 0)),\n",
    "    (3, 4., 'string3', date(2000, 3, 1), datetime(2000, 1, 3, 12, 0))\n",
    "], schema='a long, b double, c string, d date, e timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+----------+-------------------+\n",
      "|  a|  b|      c|         d|                  e|\n",
      "+---+---+-------+----------+-------------------+\n",
      "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
      "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n",
      "|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|\n",
      "+---+---+-------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZONA DE MEDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = spark.createDataFrame([\n",
    "    (\"Jorge\", 10, 8, 5, None),\n",
    "    (\"Fito\", 6, 7, 8, 10),\n",
    "    (\"Percy\", None, None, None, 5)\n",
    "],[\"Nombre\", \"Nota1\", \"Nota2\", \"Nota3\", \"Nota4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Nombre: string (nullable = true)\n",
      " |-- Nota1: long (nullable = true)\n",
      " |-- Nota2: long (nullable = true)\n",
      " |-- Nota3: long (nullable = true)\n",
      " |-- Nota4: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBTENER LAS COLUMNAS NOTAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zona de crear la lista de columnas\n",
    "columnas = [x for x in df_data.columns if \"Nota\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nota1', 'Nota2', 'Nota3', 'Nota4']\n"
     ]
    }
   ],
   "source": [
    "print(columnas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCION UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(returnType=FloatType())\n",
    "def met_media(columnas_listas):\n",
    "    suma = 0\n",
    "    contador = 0\n",
    "    for rows in columnas_listas:\n",
    "        value = rows\n",
    "        if value is not None:\n",
    "            suma +=value\n",
    "            contador +=1\n",
    "\n",
    "    if suma > 0:\n",
    "        return suma / contador\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----+-----+-----+---------+\n",
      "|Nombre|Nota1|Nota2|Nota3|Nota4|MET_MEDIA|\n",
      "+------+-----+-----+-----+-----+---------+\n",
      "| Jorge|   10|    8|    5| null|7.6666665|\n",
      "|  Fito|    6|    7|    8|   10|     7.75|\n",
      "| Percy| null| null| null|    5|      5.0|\n",
      "+------+-----+-----+-----+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_media = df_data.withColumn(\"MET_MEDIA\", met_media(array(columnas)))\n",
    "df_media.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
